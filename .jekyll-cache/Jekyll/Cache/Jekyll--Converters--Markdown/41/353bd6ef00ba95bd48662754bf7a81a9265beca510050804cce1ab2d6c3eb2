I"	<p>Precision agriculture often require images from different spectra in infrared &amp; visual for gaining nutritional information about the crop. In this project, multispectral images of a field were taken by flying a drone over the field. A method for alignment of images from different spectra was developed.</p>

<p>Infrared images differ significantly from visual-spectrum images (in terms of texture, intensity gradients, etc), so standard feature-based computer vision methods cannot be used. The project used an iterative method for maximising ‘Mattes Mutual Information’ between visual and infrared images,  for multi-channel registration. Additionally a method for estimating a prior transform between channels was developed, to move towards real-time performance.</p>

<figure class="third ">
  
    
      <a href="/assets/images/projects/imgR.png">
          <img src="/assets/images/projects/imgR.png" alt="placeholder image 1" />
      </a>
    
  
    
      <a href="/assets/images/projects/imgIR.png">
          <img src="/assets/images/projects/imgIR.png" alt="placeholder image 2" />
      </a>
    
  
    
      <a href="/assets/images/projects/imgRGIR.png">
          <img src="/assets/images/projects/imgRGIR.png" alt="placeholder image 3" />
      </a>
    
  
  
    <figcaption><strong>Image 1:</strong> Red-edge channel; <strong>Image 2:</strong> Near-IR channel; <strong>Image 3:</strong> Registered R-G-NIR image
</figcaption>
  
</figure>

<p>This project was done in July 2020  as a short, month-long project with the <a href="https://www.autonomousrobotslab.com/"><strong>Autonomous Robots Lab</strong></a> (<strong>University of Nevada, Reno</strong>), under <a href="http://www.kostasalexis.com/"><strong>Prof Kostas Alexis</strong></a>.</p>

<p><sub></sub></p>

:ET